class GlobalContextManager {
	globalContext
	siteId
	nodeId
	environment
	...

	public static refresh(){
		// logic to update global context
	} 

	public static getContext(){
		return this.globalContext
	}
}

GlobalContextManager is optional dependency for logger:
class _Logger {
	
	private enrichLog(args: LogInput) {

        args = typeof args === "string" ? { msg: args } : args

        if (process.env.SKIP_LOG_CONTEXT == "true") {
            return args;
        }

        return { ...args, ...GlobalContextManager.getContext(), ...contextStore.getStore(), ...this.settings.context }
    }
	
}
## Things to note down
1. IOT challenges, limitations and standards
2. NATS and why are we using KEUS NATS
3. Queueing systems, and differences between RabbitMQ and Kafka
4. read about molecular.js
5. apache airflow and elastisearch for data pipelining
6. never under estimate the value of missing data, 
7. fluentd - buffers, fluentxt for logging
8. 

## After scrum points
2024-12-13
1. Before IIID, the product was ad-hoc, now after december the entire code might change (clean architecture), currently developers are going to clients houses for deployment (I've also seen the demo in today's stand-up of platform-agent)
2. We make use of more interfaces (interfaces like in observer pattern)
3. We are using dev-contianers, and good logs to make rich developer experience
4. The other thing is ....

## ElasticSearch
1. rubular.com
2. elaticseach and kibana (elastic.co)
3. optmized for search and analytics
4. elasticsearch uses an inverted index for full-text search (read paper on apache lucene)
5. ElasticStack - Logs DB
6. Learn about FluentD, FluentBit and FeatBit
7. fluentbit installed in hub, and collects data
8. fluentd acts as a data pipeline (data aggregation and piplelining)
9. read about distributed nature and faut tolerance of elasticsearch


2024-12-16
1. OS updates using multiflow and PA  - Sai Kiran (16th December)
2. logratotate configuration using PA
3. global context using PA - Sai Kiran (16th December)
4. Fleutnbit regex update for pheonix os
	1. Fluentbit lua script for global context
Site Manger managing plugin updates using multi-flow - Sai Teja
- Document all cases

Keus Rasbian based Gateway
- finalize reuiqrements - Ashwik
- platform components to be installed and updated multiflow and PA

Deployments dashboard using PA(platform agent) logs - Vivek (Kibana and Elastisearch)
Hardware metrics dashboard using PA logs - Vivek
How do we handle missing data - Vivek
	- intially all deployments are manually to each Hub (deploying Platform Agent)
	- initailly X amounts of hubs are generating data, if this goes les than X, we need to generate an alert

Install platform agents in alpha homes (OS is old in alpha homes as well, $\alpha$ deployment)
- Need list of site ids to deploy PA - Rahul
- if os and pa are updating properly, efforts are reduced
- PA is ready for production

Finaloze requirements what components are required to be updated by platform agent
Do these by today only.


2025-01-08
My brain is fucking clouded, I am not able to think straight, I am zoning out so much

But let's see the working on the rules engine for a time-based event
1. Suppose that someone comes on the , for this things we are using events to start the rules, and then from rules triggers are happening which in turn ...sorry I have lost my chain of thoughts.
2. For every device that we are adding to the site we need to finalize its triggers. triggers can be things we whether a device is turning on or off, light is at brightness level 40% or what.
3. These trigger can then be used to trigger some automation
What more things that we can lookup into
1. Version Control of Rules, so that user can move back if he does want new rules to take effect
2. If the system restarts, then it should have an idea of its previous state and if some previous rules which should have triggered in the time it was shut-off so also be triggered.
3. Same triggers can be used to make different rules depending on the user's device from where the automations are being made.
4. Automations can also be specialised on the basis of where the user is
	1. for example in bedroom the same triggers can do different things
	2. and in dining room those triggers coudl do different things
	3. Simulation of what some automations would do can also be provided to the user

For now we can thing on defining the triggers and implementing those triggers on new devices

So the rules lifecycle is
1. A user decides on some triggers(ui-term), these "triggers" are facts on our rule-engine side
2. When some fact is changes then factChanges job is send, whereupon the events get emitted
3. Via these events routines are executed, inside these rountines we have triggers which are responsible for changing the state of things like TV-OFF, LIGHT-30%
PluginService is responsible for plugin-deepmedia-appletv

Guidelines
Focus less on schedules, and more on save 
1. Save Rules in db
2. Save routines in db(execute them in parallel)
3. Start rule engine  using moleculer channels

